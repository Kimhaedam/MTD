{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "764d20dc",
   "metadata": {},
   "source": [
    "참고 GitHub : https://github.com/kahramankostas/Anomaly-Detection-in-Networks-Using-Machine-Learning/blob/master/01_preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2931722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "import time\n",
    "seconds = time.time()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6651e13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"This process may take 5 to 10 minutes, depending on the performance of your computer.\\n\\n\\n\")\n",
    "number=\"0123456789\"\n",
    "# CSV 파일 이름\n",
    "csv_files=[\"Monday-WorkingHours.pcap_ISCX\",\n",
    "        \"Tuesday-WorkingHours.pcap_ISCX\",\n",
    "        \"Wednesday-workingHours.pcap_ISCX\",\n",
    "        \"Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX\",\n",
    "        \"Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX\",\n",
    "        \"Friday-WorkingHours-Morning.pcap_ISCX\",\n",
    "        \"Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX\",\n",
    "        \"Friday-WorkingHours-Afternoon-DDos.pcap_ISCX\",]\n",
    "\n",
    "# 컬럼 이름\n",
    "main_labels=[\"Flow ID\",\"Source IP\",\"Source Port\",\"Destination IP\",\"Destination Port\",\"Protocol\",\"Timestamp\",\"Flow Duration\",\"Total Fwd Packets\",\n",
    "   \"Total Backward Packets\",\"Total Length of Fwd Packets\",\"Total Length of Bwd Packets\",\"Fwd Packet Length Max\",\"Fwd Packet Length Min\",\n",
    "   \"Fwd Packet Length Mean\",\"Fwd Packet Length Std\",\"Bwd Packet Length Max\",\"Bwd Packet Length Min\",\"Bwd Packet Length Mean\",\"Bwd Packet Length Std\",\n",
    "   \"Flow Bytes/s\",\"Flow Packets/s\",\"Flow IAT Mean\",\"Flow IAT Std\",\"Flow IAT Max\",\"Flow IAT Min\",\"Fwd IAT Total\",\"Fwd IAT Mean\",\"Fwd IAT Std\",\"Fwd IAT Max\",\n",
    "   \"Fwd IAT Min\",\"Bwd IAT Total\",\"Bwd IAT Mean\",\"Bwd IAT Std\",\"Bwd IAT Max\",\"Bwd IAT Min\",\"Fwd PSH Flags\",\"Bwd PSH Flags\",\"Fwd URG Flags\",\"Bwd URG Flags\",\n",
    "   \"Fwd Header Length\",\"Bwd Header Length\",\"Fwd Packets/s\",\"Bwd Packets/s\",\"Min Packet Length\",\"Max Packet Length\",\"Packet Length Mean\",\"Packet Length Std\",\n",
    "   \"Packet Length Variance\",\"FIN Flag Count\",\"SYN Flag Count\",\"RST Flag Count\",\"PSH Flag Count\",\"ACK Flag Count\",\"URG Flag Count\",\"CWE Flag Count\",\n",
    "   \"ECE Flag Count\",\"Down/Up Ratio\",\"Average Packet Size\",\"Avg Fwd Segment Size\",\"Avg Bwd Segment Size\",\"faulty-Fwd Header Length\",\"Fwd Avg Bytes/Bulk\",\n",
    "   \"Fwd Avg Packets/Bulk\",\"Fwd Avg Bulk Rate\",\"Bwd Avg Bytes/Bulk\",\"Bwd Avg Packets/Bulk\",\"Bwd Avg Bulk Rate\",\"Subflow Fwd Packets\",\"Subflow Fwd Bytes\",\n",
    "   \"Subflow Bwd Packets\",\"Subflow Bwd Bytes\",\"Init_Win_bytes_forward\",\"Init_Win_bytes_backward\",\"act_data_pkt_fwd\",\n",
    "   \"min_seg_size_forward\",\"Active Mean\",\"Active Std\",\"Active Max\",\"Active Min\",\"Idle Mean\",\"Idle Std\",\"Idle Max\",\"Idle Min\",\"Label\",\"External IP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfa5280",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_labels2=main_labels\n",
    "main_labels=( \",\".join( i for i in main_labels ) )\n",
    "main_labels=main_labels+\"\\n\"\n",
    "flag=True\n",
    "for i in range(len(csv_files)):\n",
    "    ths = open(str(i)+\".csv\", \"w\")\n",
    "    ths.write(main_labels)\n",
    "    with open(\"./CSVs/\"+csv_files[i]+\".csv\", \"r\") as file:\n",
    "        while True:\n",
    "            try:\n",
    "                line=file.readline()\n",
    "                if  line[0] in number: # CSV 파일 및 불완전한 스트림의 헤더를 제거\n",
    "                    if \" – \" in str(line): # # \"-\" 문자(\"-\", 유니코드 코드:8211)가 있으면 \"-\" 문자(유니코드 코드:45)로 바꾸기\n",
    "                        line=(str(line).replace(\" – \",\" - \"))\n",
    "                    line=(str(line).replace(\"inf\",\"0\"))\n",
    "                    line=(str(line).replace(\"Infinity\",\"0\"))\n",
    "                    line=(str(line).replace(\"NaN\",\"0\"))\n",
    "                     \n",
    "                    ths.write(str(line))\n",
    "                else:\n",
    "                    continue                       \n",
    "            except:\n",
    "                break\n",
    "    ths.close()\n",
    " \n",
    " \n",
    "    df=pd.read_csv(str(i)+\".csv\",low_memory=False)\n",
    "    df=df.fillna(0)\n",
    "\n",
    "    string_features=[\"Flow Bytes/s\",\"Flow Packets/s\"]\n",
    "    for ii in string_features: # Flow Bytes / s, Flow Packets / s 등 숫자가 아닌 데이터 변환\n",
    "        df[ii]=df[ii].replace('Infinity', -1)\n",
    "        df[ii]=df[ii].replace('NaN', 0)\n",
    "        number_or_not=[]\n",
    "        for iii in df[ii]:\n",
    "            try:\n",
    "                k=int(float(iii))\n",
    "                number_or_not.append(int(k))\n",
    "            except:\n",
    "                number_or_not.append(iii)\n",
    "        df[ii]=number_or_not\n",
    "\n",
    "\n",
    "\n",
    "    string_features=[]\n",
    "    for j in main_labels2: # 문자열, 범주형 등 숫자가 아닌 컬럼 탐지\n",
    "        if df[j].dtype==\"object\":\n",
    "            string_features.append(j)\n",
    "    try:\n",
    "        string_features.remove('Label')\n",
    "    except:\n",
    "        print(\"error!\")\n",
    "    labelencoder_X = preprocessing.LabelEncoder()\n",
    "\n",
    "\n",
    "\n",
    "    for ii in string_features: # 문자열, 범주형 등 숫자가 아닌 컬럼을 숫자로 변환\n",
    "        try:\n",
    "            df[ii]=labelencoder_X.fit_transform(df[ii])\n",
    "        except:\n",
    "            df[ii]=df[ii].replace('Infinity', -1)\n",
    "    df=df.drop(main_labels2[61], axis=1) \n",
    "\n",
    "\n",
    "\n",
    "    ##All CSV files are merged into a single file.\n",
    "    if flag:\n",
    "        df.to_csv('all_data.csv' ,index = False)\n",
    "        flag=False\n",
    "    else:\n",
    "        df.to_csv('all_data.csv' ,index = False,header=False,mode=\"a\")\n",
    "    os.remove(str(i)+\".csv\")\n",
    "    print(\"The pre-processing phase of the \",csv_files[i],\" file is completed.\\n\")\n",
    "    \n",
    "\n",
    "print(\"mission accomplished!\")\n",
    "print(\"Total operation time: = \",time.time()- seconds ,\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df306089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
